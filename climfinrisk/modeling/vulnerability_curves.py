"""
Advanced vulnerability curves module with adaptive asset-specific functions.
"""

import logging
from typing import Dict, List, Optional, Union, Tuple, Any, Callable
import numpy as np
import pandas as pd
import xarray as xr
from scipy import stats, optimize
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern
import warnings

logger = logging.getLogger(__name__)


class VulnerabilityCurves:
    """
    Advanced vulnerability curve modeling with adaptive, asset-specific functions.
    
    Novel Features:
    - Dynamic vulnerability curves that adapt based on asset characteristics
    - Bayesian updating with historical loss data
    - Multi-hazard vulnerability interactions
    - Uncertainty quantification for damage estimates
    """
    
    def __init__(self, config=None):
        """
        Initialize vulnerability curve modeler.
        
        Args:
            config: Configuration object with vulnerability parameters
        """
        self.config = config or {}
        self.vulnerability_models = {}
        self.historical_calibration = {}
        
    def create_adaptive_vulnerability_curve(
        self,
        asset_characteristics: Dict[str, Any],
        hazard_type: str,
        historical_losses: Optional[pd.DataFrame] = None
    ) -> Callable[[np.ndarray], Tuple[np.ndarray, np.ndarray]]:
        """
        Create an adaptive vulnerability curve for a specific asset.
        
        Args:
            asset_characteristics: Asset properties (age, construction, etc.)
            hazard_type: Type of climate hazard
            historical_losses: Historical loss data for calibration
            
        Returns:
            Function that maps hazard intensity to (damage_ratio, uncertainty)
        """
        logger.info(f"Creating adaptive vulnerability curve for {hazard_type}")
        
        base_params = self._get_base_vulnerability_params(hazard_type)
        
        adjusted_params = self._adjust_for_asset_characteristics(
            base_params, asset_characteristics
        )
        
        if historical_losses is not None:
            calibrated_params = self._calibrate_with_historical_data(
                adjusted_params, historical_losses, hazard_type
            )
        else:
            calibrated_params = adjusted_params
        
        def vulnerability_function(hazard_intensity: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
            """
            Calculate damage ratio and uncertainty for given hazard intensity.
            
            Args:
                hazard_intensity: Array of hazard intensity values
                
            Returns:
                Tuple of (damage_ratio, uncertainty_std)
            """
            return self._calculate_damage_with_uncertainty(
                hazard_intensity, calibrated_params
            )
        
        model_key = f"{hazard_type}_{hash(str(asset_characteristics))}"
        self.vulnerability_models[model_key] = {
            'function': vulnerability_function,
            'parameters': calibrated_params,
            'asset_characteristics': asset_characteristics,
            'hazard_type': hazard_type
        }
        
        return vulnerability_function
    
    def model_multi_hazard_interactions(
        self,
        hazard_intensities: Dict[str, np.ndarray],
        asset_characteristics: Dict[str, Any]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Model vulnerability to multiple simultaneous hazards.
        
        Args:
            hazard_intensities: Dictionary of hazard types and their intensities
            asset_characteristics: Asset properties
            
        Returns:
            Tuple of (combined_damage_ratio, uncertainty)
        """
        logger.info("Modeling multi-hazard vulnerability interactions")
        
        individual_damages = {}
        individual_uncertainties = {}
        
        for hazard_type, intensity in hazard_intensities.items():
            vuln_func = self.create_adaptive_vulnerability_curve(
                asset_characteristics, hazard_type
            )
            damage, uncertainty = vuln_func(intensity)
            individual_damages[hazard_type] = damage
            individual_uncertainties[hazard_type] = uncertainty
        
        combined_damage, combined_uncertainty = self._combine_multi_hazard_effects(
            individual_damages, individual_uncertainties, asset_characteristics
        )
        
        return combined_damage, combined_uncertainty
    
    def update_vulnerability_with_new_data(
        self,
        model_key: str,
        new_loss_data: pd.DataFrame
    ):
        """
        Update vulnerability curve with new loss observations (Bayesian updating).
        
        Args:
            model_key: Identifier for the vulnerability model
            new_loss_data: New loss observations
        """
        if model_key not in self.vulnerability_models:
            logger.warning(f"Model {model_key} not found")
            return
        
        logger.info(f"Updating vulnerability model {model_key} with new data")
        
        model = self.vulnerability_models[model_key]
        current_params = model['parameters']
        
        updated_params = self._bayesian_parameter_update(
            current_params, new_loss_data, model['hazard_type']
        )
        
        model['parameters'] = updated_params
        
        def updated_vulnerability_function(hazard_intensity: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
            return self._calculate_damage_with_uncertainty(
                hazard_intensity, updated_params
            )
        
        model['function'] = updated_vulnerability_function
        
        logger.info(f"Model {model_key} updated successfully")
    
    def generate_vulnerability_surface(
        self,
        hazard_range: np.ndarray,
        asset_characteristics: Dict[str, Any],
        hazard_type: str,
        confidence_levels: List[float] = [0.05, 0.95]
    ) -> Dict[str, np.ndarray]:
        """
        Generate vulnerability surface with confidence intervals.
        
        Args:
            hazard_range: Range of hazard intensities to evaluate
            asset_characteristics: Asset properties
            hazard_type: Type of climate hazard
            confidence_levels: Confidence levels for uncertainty bands
            
        Returns:
            Dictionary with damage estimates and confidence intervals
        """
        vuln_func = self.create_adaptive_vulnerability_curve(
            asset_characteristics, hazard_type
        )
        
        damage_ratios, uncertainties = vuln_func(hazard_range)
        
        confidence_intervals = {}
        for conf_level in confidence_levels:
            z_score = stats.norm.ppf(conf_level)
            confidence_intervals[f'ci_{int(conf_level*100)}'] = damage_ratios + z_score * uncertainties
        
        return {
            'hazard_intensity': hazard_range,
            'damage_ratio': damage_ratios,
            'uncertainty': uncertainties,
            **confidence_intervals
        }
    
    def _get_base_vulnerability_params(self, hazard_type: str) -> Dict[str, float]:
        """Get base vulnerability parameters for hazard type."""
        base_params = {
            'flood': {
                'threshold': 0.1,
                'slope': 0.8,
                'max_damage': 0.9,
                'shape_param': 2.0,
                'uncertainty_base': 0.15
            },
            'cyclone': {
                'threshold': 0.15,
                'slope': 0.9,
                'max_damage': 0.95,
                'shape_param': 1.8,
                'uncertainty_base': 0.20
            },
            'drought': {
                'threshold': 0.2,
                'slope': 0.6,
                'max_damage': 0.7,
                'shape_param': 1.5,
                'uncertainty_base': 0.25
            },
            'wildfire': {
                'threshold': 0.05,
                'slope': 1.2,
                'max_damage': 0.98,
                'shape_param': 2.5,
                'uncertainty_base': 0.18
            }
        }
        
        return base_params.get(hazard_type, base_params['flood'])
    
    def _adjust_for_asset_characteristics(
        self,
        base_params: Dict[str, float],
        asset_characteristics: Dict[str, Any]
    ) -> Dict[str, float]:
        """Adjust vulnerability parameters based on asset characteristics."""
        adjusted_params = base_params.copy()
        
        construction_type = asset_characteristics.get('construction_type', 'standard')
        construction_multipliers = {
            'reinforced': {'slope': 0.7, 'max_damage': 0.8, 'uncertainty_base': 0.8},
            'standard': {'slope': 1.0, 'max_damage': 1.0, 'uncertainty_base': 1.0},
            'vulnerable': {'slope': 1.3, 'max_damage': 1.1, 'uncertainty_base': 1.2}
        }
        
        multiplier = construction_multipliers.get(construction_type, construction_multipliers['standard'])
        for param in ['slope', 'max_damage', 'uncertainty_base']:
            adjusted_params[param] *= multiplier[param]
        
        age = asset_characteristics.get('age', 20)
        age_factor = 1 + (age - 20) * 0.01  # 1% increase per year above 20
        adjusted_params['slope'] *= max(0.5, age_factor)
        adjusted_params['uncertainty_base'] *= max(0.8, age_factor)
        
        adaptation_score = asset_characteristics.get('adaptation_score', 0.5)
        adaptation_factor = 1 - adaptation_score * 0.3  # Up to 30% reduction
        adjusted_params['slope'] *= adaptation_factor
        adjusted_params['max_damage'] *= adaptation_factor
        
        adjusted_params['max_damage'] = min(1.0, adjusted_params['max_damage'])
        adjusted_params['slope'] = max(0.1, adjusted_params['slope'])
        adjusted_params['uncertainty_base'] = max(0.05, adjusted_params['uncertainty_base'])
        
        return adjusted_params
    
    def _calibrate_with_historical_data(
        self,
        params: Dict[str, float],
        historical_losses: pd.DataFrame,
        hazard_type: str
    ) -> Dict[str, float]:
        """Calibrate vulnerability parameters using historical loss data."""
        if len(historical_losses) < 3:
            logger.warning("Insufficient historical data for calibration")
            return params
        
        try:
            intensity_col = f'{hazard_type}_intensity'
            damage_col = 'damage_ratio'
            
            if intensity_col not in historical_losses.columns or damage_col not in historical_losses.columns:
                logger.warning("Required columns not found in historical data")
                return params
            
            intensities = historical_losses[intensity_col].values
            damages = historical_losses[damage_col].values
            
            def vulnerability_func(intensity, threshold, slope, max_damage, shape_param):
                normalized_intensity = np.maximum(0, intensity - threshold)
                damage = max_damage * (1 - np.exp(-slope * normalized_intensity ** shape_param))
                return np.clip(damage, 0, max_damage)
            
            def objective(params_array):
                threshold, slope, max_damage, shape_param = params_array
                predicted_damages = vulnerability_func(intensities, threshold, slope, max_damage, shape_param)
                return np.sum((predicted_damages - damages) ** 2)
            
            initial_params = [
                params['threshold'],
                params['slope'],
                params['max_damage'],
                params['shape_param']
            ]
            
            bounds = [
                (0, 0.5),      # threshold
                (0.1, 3.0),    # slope
                (0.3, 1.0),    # max_damage
                (0.5, 5.0)     # shape_param
            ]
            
            result = optimize.minimize(
                objective,
                initial_params,
                bounds=bounds,
                method='L-BFGS-B'
            )
            
            if result.success:
                calibrated_params = params.copy()
                calibrated_params['threshold'] = result.x[0]
                calibrated_params['slope'] = result.x[1]
                calibrated_params['max_damage'] = result.x[2]
                calibrated_params['shape_param'] = result.x[3]
                
                logger.info("Vulnerability parameters calibrated successfully")
                return calibrated_params
            else:
                logger.warning("Parameter optimization failed, using default parameters")
                return params
                
        except Exception as e:
            logger.error(f"Calibration failed: {e}")
            return params
    
    def _calculate_damage_with_uncertainty(
        self,
        hazard_intensity: np.ndarray,
        params: Dict[str, float]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Calculate damage ratio and uncertainty for given hazard intensity."""
        intensity = np.asarray(hazard_intensity)
        
        threshold = params['threshold']
        slope = params['slope']
        max_damage = params['max_damage']
        shape_param = params['shape_param']
        
        normalized_intensity = np.maximum(0, intensity - threshold)
        
        damage_ratio = max_damage * (1 - np.exp(-slope * normalized_intensity ** shape_param))
        damage_ratio = np.clip(damage_ratio, 0, max_damage)
        
        base_uncertainty = params['uncertainty_base']
        intensity_dependent_uncertainty = base_uncertainty * (1 + 0.5 * normalized_intensity)
        damage_dependent_uncertainty = 0.1 * damage_ratio * (1 - damage_ratio / max_damage)
        
        total_uncertainty = np.sqrt(
            intensity_dependent_uncertainty ** 2 + damage_dependent_uncertainty ** 2
        )
        
        return damage_ratio, total_uncertainty
    
    def _combine_multi_hazard_effects(
        self,
        individual_damages: Dict[str, np.ndarray],
        individual_uncertainties: Dict[str, np.ndarray],
        asset_characteristics: Dict[str, Any]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Combine effects of multiple hazards with interaction terms."""
        hazard_types = list(individual_damages.keys())
        
        if len(hazard_types) == 1:
            hazard_type = hazard_types[0]
            return individual_damages[hazard_type], individual_uncertainties[hazard_type]
        
        damages = np.array(list(individual_damages.values()))
        uncertainties = np.array(list(individual_uncertainties.values()))
        
        combined_damage = 1 - np.prod(1 - damages, axis=0)
        
        interaction_factor = self._calculate_interaction_factor(
            hazard_types, asset_characteristics
        )
        
        combined_damage *= interaction_factor
        
        combined_uncertainty = np.sqrt(np.sum(uncertainties ** 2, axis=0))
        
        combined_damage = np.clip(combined_damage, 0, 1)
        
        return combined_damage, combined_uncertainty
    
    def _calculate_interaction_factor(
        self,
        hazard_types: List[str],
        asset_characteristics: Dict[str, Any]
    ) -> float:
        """Calculate interaction factor for multiple hazards."""
        interaction_effects = {
            ('flood', 'cyclone'): 1.2,      # Compound flooding
            ('drought', 'wildfire'): 1.3,   # Drought increases fire risk
            ('cyclone', 'flood'): 1.15,     # Storm surge + rainfall
            ('flood', 'drought'): 0.9,      # Opposite effects
        }
        
        for hazard_pair, factor in interaction_effects.items():
            if all(hazard in hazard_types for hazard in hazard_pair):
                return factor
        
        if len(hazard_types) > 2:
            return 1.1  # Slight amplification for multiple hazards
        else:
            return 1.05  # Minimal interaction for two hazards
    
    def _bayesian_parameter_update(
        self,
        current_params: Dict[str, float],
        new_data: pd.DataFrame,
        hazard_type: str
    ) -> Dict[str, float]:
        """Update parameters using Bayesian inference."""
        
        try:
            intensity_col = f'{hazard_type}_intensity'
            damage_col = 'damage_ratio'
            
            if intensity_col not in new_data.columns or damage_col not in new_data.columns:
                return current_params
            
            intensities = new_data[intensity_col].values
            damages = new_data[damage_col].values
            
            predicted_damages, _ = self._calculate_damage_with_uncertainty(
                intensities, current_params
            )
            
            residuals = damages - predicted_damages
            mean_residual = np.mean(residuals)
            
            updated_params = current_params.copy()
            if abs(mean_residual) > 0.05:  # Significant bias
                adjustment_factor = 1 + mean_residual * 0.1
                updated_params['slope'] *= adjustment_factor
                updated_params['slope'] = np.clip(updated_params['slope'], 0.1, 3.0)
            
            return updated_params
            
        except Exception as e:
            logger.error(f"Bayesian update failed: {e}")
            return current_params
    
    def export_vulnerability_models(self, output_path: str):
        """Export vulnerability models for reuse."""
        import pickle
        
        export_data = {
            'models': {},
            'metadata': {
                'version': '1.0',
                'created_at': pd.Timestamp.now().isoformat()
            }
        }
        
        for model_key, model in self.vulnerability_models.items():
            export_data['models'][model_key] = {
                'parameters': model['parameters'],
                'asset_characteristics': model['asset_characteristics'],
                'hazard_type': model['hazard_type']
            }
        
        with open(output_path, 'wb') as f:
            pickle.dump(export_data, f)
        
        logger.info(f"Vulnerability models exported to {output_path}")
    
    def load_vulnerability_models(self, input_path: str):
        """Load previously saved vulnerability models."""
        import pickle
        
        try:
            with open(input_path, 'rb') as f:
                export_data = pickle.load(f)
            
            for model_key, model_data in export_data['models'].items():
                params = model_data['parameters']
                
                def vulnerability_function(hazard_intensity: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
                    return self._calculate_damage_with_uncertainty(hazard_intensity, params)
                
                self.vulnerability_models[model_key] = {
                    'function': vulnerability_function,
                    'parameters': params,
                    'asset_characteristics': model_data['asset_characteristics'],
                    'hazard_type': model_data['hazard_type']
                }
            
            logger.info(f"Vulnerability models loaded from {input_path}")
            
        except Exception as e:
            logger.error(f"Failed to load vulnerability models: {e}")
